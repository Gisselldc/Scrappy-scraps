#sample code
import spacy
import os

# Load spaCy's English model
nlp = spacy.load("en_core_web_sm")

# Define input and output directories
input_directory = "/Users/gisselldc/Comp Docs/Blogs Project/Open AI/News"  # Folder with your text files
output_directory = "/Users/gisselldc/Comp Docs/Blogs Project/Open AI/News/processed"  # Folder for processed files

# Ensure the output directory exists
os.makedirs(output_directory, exist_ok=True)

# Process each file in the directory
for filename in os.listdir(input_directory):
    if filename.endswith(".txt"):  # Process only text files
        file_path = os.path.join(input_directory, filename)

        # Read the file content
        with open(file_path, "r", encoding="utf-8") as file:
            text = file.read()

        # Process the text with spaCy
        doc = nlp(text)

        # Extract named entities
        entities = [(ent.text, ent.label_) for ent in doc.ents]

        # Save results to a new file
        output_path = os.path.join(output_directory, f"processed_{filename}")
        with open(output_path, "w", encoding="utf-8") as out_file:
            out_file.write(f"Processed File: {filename}\n\n")
            out_file.write("Named Entities:\n")
            for text, label in entities:
                out_file.write(f"{text} - {label}\n")

        print(f"âœ… Processed: {filename} â†’ Saved to {output_path}")

print("ðŸŽ‰ All files processed successfully!")
